Scope of the Survey: AI/ML Dataflow Graph Scheduling

The execution of AI/ML models heavily relies on efficient dataflow graph scheduling, where computational tasks are represented as directed acyclic graphs (DAGs). These graphs dictate the execution order of operations, making optimal scheduling crucial for improving computational efficiency, reducing latency, and maximizing resource utilization.

This survey will explore three core dimensions of AI/ML dataflow graph scheduling:
	•	Algorithmic Techniques: Investigating scheduling algorithms such as list scheduling, priority-based heuristics, critical path methods, and task graph partitioning. We will analyze their computational complexity, trade-offs, and applicability to AI/ML workloads.
	•	High-Performance Computing (HPC) Considerations: Exploring how scheduling affects parallel computing on GPUs, TPUs, and multi-core architectures, along with memory-aware optimizations and distributed execution strategies.
	•	ML-Based Scheduling Approaches: Examining reinforcement learning and neural network-driven auto-scheduling techniques used in frameworks like TensorFlow XLA, Apache TVM, and PyTorch TorchScript.

By synthesizing state-of-the-art research, this survey will provide a comparative analysis of scheduling strategies, highlight existing challenges, and identify future research directions for improving scheduling efficiency in AI/ML workflows.
